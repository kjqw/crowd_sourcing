{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルとトークナイザーのロード\n",
    "model_name = \"meta-llama/Llama-2-7b\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "model = LlamaForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# トークン数を記録する変数を初期化\n",
    "total_input_tokens = 0\n",
    "total_output_tokens = 0\n",
    "\n",
    "# .envファイルのロード\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=Path(\"./data/.env\"))\n",
    "\n",
    "# モデルのコスト情報のロード\n",
    "with open(\"./data/model_costs.json\", \"r\") as f:\n",
    "    model_costs = json.load(f)\n",
    "\n",
    "# ラベルのロード\n",
    "with open(\"./data/labels.json\", \"r\") as f:\n",
    "    labels = json.load(f)[\"labels\"]\n",
    "\n",
    "# 元データのデータフレームのロード\n",
    "with open(\"data/df_batches.pkl\", \"rb\") as f:\n",
    "    df_batches = pickle.load(f)\n",
    "\n",
    "# 元データの辞書のロード\n",
    "with open(\"data/original_data_dict.pkl\", \"rb\") as f:\n",
    "    original_data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_evaluate(\n",
    "    texts_dict: dict[str], labels: list[str], model, tokenizer\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    文章を指定されたラベルに分類し、満足か不満かを判断する関数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts_dict : dict[str]\n",
    "        分類する文章の辞書\n",
    "    labels : list[str]\n",
    "        分類するラベル\n",
    "    model : LlamaForCausalLM\n",
    "        使用するモデル\n",
    "    tokenizer : LlamaTokenizer\n",
    "        使用するトークナイザー\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        分類結果と満足度の判定結果\n",
    "    \"\"\"\n",
    "    global total_input_tokens, total_output_tokens\n",
    "\n",
    "    results = {}\n",
    "    for text_id, text in texts_dict.items():\n",
    "        prompt = (\n",
    "            f\"与えられた文章を次のようなラベルの1つに分類してください: {labels}。\\n\"\n",
    "            f\"次に、その文章が満足か不満のどちらであるかを判断してください。\\n\"\n",
    "            f\"出力の形式は次のような辞書型にしてください: {{text_id : {{'label': 'ラベル名', 'sentiment': '満足' または '不満'}}}}。\\n\"\n",
    "            f\"文章: {text}\"\n",
    "        )\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        total_input_tokens += len(inputs[\"input_ids\"][0])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_length=100)\n",
    "        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        total_output_tokens += len(outputs[0])\n",
    "\n",
    "        # 結果を辞書にパースして追加\n",
    "        result = ast.literal_eval(generated_text.strip().split(\"\\n\")[-1])\n",
    "        results[text_id] = result\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストの分類と評価の実行\n",
    "texts_dict = {\"1\": \"この製品は非常に良いです。\", \"2\": \"サービスが悪かったです。\"}\n",
    "results = classify_and_evaluate(texts_dict, labels, model, tokenizer)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
