{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークン数を記録する変数を初期化\n",
    "total_input_tokens = 0\n",
    "total_output_tokens = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するモデルの設定\n",
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "\n",
    "# 文章データの最小文字数\n",
    "# min_length = 10\n",
    "min_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .envファイルのロード\n",
    "load_dotenv(dotenv_path=Path(\"data/.env\"))\n",
    "\n",
    "# OpenAI APIキーの設定\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# 元データのロード\n",
    "df_data = pd.read_csv(\n",
    "    f\"/workspace/crowd_sourcing/demo/bert/data/data_long_texts_{min_length}.tsv\",\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "# カラム名の変更\n",
    "df_data.columns = [\"label\", \"satisfaction\", \"text\", \"ID\"]\n",
    "df_data = df_data[[\"label\", \"satisfaction\", \"text\"]]\n",
    "\n",
    "# バッチデータのロード\n",
    "with open(f\"data/df_batches_{min_length}.pickle\", \"rb\") as f:\n",
    "    df_batches = pickle.load(f)\n",
    "\n",
    "# モデルのコスト情報のロード\n",
    "with open(\"model_costs.json\", \"r\") as f:\n",
    "    model_costs = json.load(f)\n",
    "\n",
    "# ラベルのロード\n",
    "with open(\"labels.json\", \"r\") as f:\n",
    "    labels = json.load(f)[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_request(texts_dict: dict[str], labels: list[str], model: str) -> dict:\n",
    "    \"\"\"\n",
    "    文章を指定されたラベルに分類し、満足か不満かを判断する関数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts_dict : dict[str]\n",
    "        分類する文章の辞書\n",
    "    labels : list[str]\n",
    "        分類するラベル\n",
    "    model : str\n",
    "        使用するモデル\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        分類結果と満足度の判定結果\n",
    "    \"\"\"\n",
    "\n",
    "    global total_input_tokens, total_output_tokens\n",
    "\n",
    "    try:\n",
    "        # OpenAI APIリクエストの作成\n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                # {\n",
    "                #     \"role\": \"system\",\n",
    "                #     \"content\": \"あなたは、テキストを事前定義されたラベルに分類し、満足度を評価するアシスタントです。\",\n",
    "                # },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"与えられた文章を次のようなラベルの1つに分類してください: {labels}。\"\n",
    "                    + \"\\n次に、その文章が満足か不満のどちらであるかを判断してください。\\n出力の形式は次のような辞書型にしてください: {text_id : {'label_prediction': 'ラベル名', 'satisfaction_prediction': '満足' または '不満'}, text_id: ...}。\"\n",
    "                    + f\"\\n文章: {texts_dict}\",\n",
    "                },\n",
    "            ],\n",
    "            temperature=1.0,\n",
    "            # max_tokens=100,\n",
    "        )\n",
    "\n",
    "        # レスポンスからトークン数を取得\n",
    "        input_tokens = response.usage.prompt_tokens\n",
    "        output_tokens = response.usage.completion_tokens\n",
    "        total_input_tokens += input_tokens\n",
    "        total_output_tokens += output_tokens\n",
    "\n",
    "        # 結果の抽出\n",
    "        result_text = response.choices[0].message.content\n",
    "        # 文字列を辞書型に変換\n",
    "        result_dict = ast.literal_eval(result_text)\n",
    "\n",
    "        return {\n",
    "            \"result_dict\": result_dict,\n",
    "            \"input_tokens\": input_tokens,\n",
    "            \"output_tokens\": output_tokens,\n",
    "            \"response\": response,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "def calculate_cost(input_tokens: int, output_tokens: int, model_name: str) -> float:\n",
    "    \"\"\"\n",
    "    使用したトークン数に基づいてコストを計算する関数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_tokens : int\n",
    "        入力トークン数\n",
    "    output_tokens : int\n",
    "        出力トークン数\n",
    "    model_name : str\n",
    "        使用したモデルの名前\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        トークン数に基づいて計算されたコスト(単位: USD)\n",
    "    \"\"\"\n",
    "\n",
    "    input_cost = input_tokens / 1e6 * model_costs[model_name][\"input\"]\n",
    "    output_cost = output_tokens / 1e6 * model_costs[model_name][\"output\"]\n",
    "    return input_cost + output_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "response_log = []\n",
    "\n",
    "for i, df_batch in enumerate(df_batches):\n",
    "    # インデックスをキー、文章を値とする辞書に変換\n",
    "    texts_dict = df_batch[\"文章\"].to_dict()\n",
    "\n",
    "    # 分類と評価を実行\n",
    "    response = api_request(texts_dict, labels, MODEL_NAME)\n",
    "\n",
    "    # 応答を記録\n",
    "    response_log.append(response)\n",
    "    result_dict.update(response[\"result_dict\"])\n",
    "\n",
    "    # 途中経過を表示\n",
    "    print(f\"Batch {i + 1} / {len(df_batches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ログを保存\n",
    "with open(f\"data/response_log_{min_length}.pickle\", \"wb\") as f:\n",
    "    pickle.dump(response_log, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果をデータフレームに変換\n",
    "df_result = pd.DataFrame(result_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# こちらが要求する形式になっていないものを抽出\n",
    "df_invalid = df_result[\n",
    "    (\n",
    "        (df_result[\"satisfaction_prediction\"] != \"満足\")\n",
    "        & (df_result[\"satisfaction_prediction\"] != \"不満\")\n",
    "    )  # 満足度の予測が指定したものでないもの\n",
    "    | ~(\n",
    "        df_result[\"label_prediction\"].isin(labels)\n",
    "    )  # ラベルの予測が指定したものでないもの\n",
    "]\n",
    "\n",
    "df_invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_invalidをdf_resultから取り除く\n",
    "df_valid = df_result[~df_result.index.isin(df_invalid.index)]\n",
    "\n",
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = pd.concat([df_valid, df_data], axis=1)  # 元データと結果を結合\n",
    "df_compare[\"is_match_label\"] = (\n",
    "    df_compare[\"label\"] == df_compare[\"label_prediction\"]\n",
    ")  # ラベルの一致を判定\n",
    "df_compare[\"is_match_satisfaction\"] = (\n",
    "    df_compare[\"satisfaction\"] == df_compare[\"satisfaction_prediction\"]\n",
    ")  # 満足度の一致を判定\n",
    "df_compare = df_compare.dropna()  # 欠損値を取り除く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解率の計算\n",
    "accuracy_label = df_compare[\"is_match_label\"].mean()\n",
    "accuracy_satisfaction = df_compare[\"is_match_satisfaction\"].mean()\n",
    "\n",
    "# コストの計算\n",
    "total_cost = calculate_cost(total_input_tokens, total_output_tokens, MODEL_NAME)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"正解率(ラベル): {accuracy_label:.2%}\")\n",
    "print(f\"正解率(満足度): {accuracy_satisfaction:.2%}\")\n",
    "print(f\"コスト: ${total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/df_compare_{MODEL_NAME}_{min_length}.pickle\", \"wb\") as f:\n",
    "    pickle.dump(df_compare, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
