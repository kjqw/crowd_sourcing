{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークン数を記録する変数を初期化\n",
    "total_input_tokens = 0\n",
    "total_output_tokens = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するモデルの設定\n",
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "\n",
    "# .envファイルのロード\n",
    "load_dotenv(dotenv_path=Path(\"./data/.env\"))\n",
    "\n",
    "# OpenAI APIキーの設定\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# モデルのコスト情報のロード\n",
    "with open(\"./data/model_costs.json\", \"r\") as f:\n",
    "    model_costs = json.load(f)\n",
    "\n",
    "# ラベルのロード\n",
    "with open(\"./data/labels.json\", \"r\") as f:\n",
    "    labels = json.load(f)[\"labels\"]\n",
    "\n",
    "# 元データのデータフレームのロード\n",
    "with open(\"data/df_batches.pkl\", \"rb\") as f:\n",
    "    df_batches = pickle.load(f)\n",
    "\n",
    "# 元データの辞書のロード\n",
    "with open(\"data/original_data_dict.pkl\", \"rb\") as f:\n",
    "    original_data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_evaluate(texts_dict: dict[str], labels: list[str], model: str) -> dict:\n",
    "    \"\"\"\n",
    "    文章を指定されたラベルに分類し、満足か不満かを判断する関数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts_dict : dict[str]\n",
    "        分類する文章の辞書\n",
    "    labels : list[str]\n",
    "        分類するラベル\n",
    "    model : str\n",
    "        使用するモデル\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        分類結果と満足度の判定結果\n",
    "    \"\"\"\n",
    "\n",
    "    global total_input_tokens, total_output_tokens\n",
    "\n",
    "    try:\n",
    "        # OpenAI APIリクエストの作成\n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                # {\n",
    "                #     \"role\": \"system\",\n",
    "                #     \"content\": \"あなたは、テキストを事前定義されたラベルに分類し、満足度を評価するアシスタントです。\",\n",
    "                # },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"与えられた文章を次のようなラベルの1つに分類してください: {labels}。\"\n",
    "                    + \"\\n次に、その文章が満足か不満のどちらであるかを判断してください。\\n出力の形式は次のような辞書型にしてください: {text_id : {'label': 'ラベル名', 'sentiment': '満足' または '不満'}, text_id: ...}。\"\n",
    "                    + f\"\\n文章: {texts_dict}\",\n",
    "                },\n",
    "            ],\n",
    "            temperature=1.0,\n",
    "            # max_tokens=100,\n",
    "        )\n",
    "\n",
    "        # レスポンスからトークン数を取得\n",
    "        input_tokens = response.usage.prompt_tokens\n",
    "        output_tokens = response.usage.completion_tokens\n",
    "        total_input_tokens += input_tokens\n",
    "        total_output_tokens += output_tokens\n",
    "\n",
    "        # 結果の抽出\n",
    "        result_text = response.choices[0].message.content\n",
    "        # 文字列を辞書型に変換\n",
    "        result_dict = ast.literal_eval(result_text)\n",
    "\n",
    "        return {\n",
    "            \"result_dict\": result_dict,\n",
    "            \"input_tokens\": input_tokens,\n",
    "            \"output_tokens\": output_tokens,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "# def evaluate_result(result_dict: dict[str], labels: list[str]) -> dict:\n",
    "\n",
    "\n",
    "def calculate_cost(input_tokens: int, output_tokens: int, model_name: str) -> float:\n",
    "    \"\"\"\n",
    "    使用したトークン数に基づいてコストを計算する関数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_tokens : int\n",
    "        入力トークン数\n",
    "    output_tokens : int\n",
    "        出力トークン数\n",
    "    model_name : str\n",
    "        使用したモデルの名前\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        トークン数に基づいて計算されたコスト(単位: USD)\n",
    "    \"\"\"\n",
    "\n",
    "    input_cost = input_tokens / 1e6 * model_costs[model_name][\"input\"]\n",
    "    output_cost = output_tokens / 1e6 * model_costs[model_name][\"output\"]\n",
    "    return input_cost + output_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "\n",
    "for df_batch in df_batches:\n",
    "    # インデックスをキー、文章を値とする辞書に変換\n",
    "    texts_dict = df_batch[\"文章\"].to_dict()\n",
    "\n",
    "    # 分類と評価を実行\n",
    "    result = classify_and_evaluate(texts_dict, labels, MODEL_NAME)\n",
    "    result_dict.update(result[\"result_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = pd.DataFrame(\n",
    "    {\n",
    "        \"original\": {\n",
    "            key: {\n",
    "                inner_key: inner_val\n",
    "                for inner_key, inner_val in val.items()\n",
    "                if inner_key != \"text\"\n",
    "            }\n",
    "            for key, val in original_data_dict.items()\n",
    "        },\n",
    "        \"predicted\": result_dict,\n",
    "    }\n",
    ")\n",
    "\n",
    "# text列を追加\n",
    "df_compare[\"text\"] = {key: val[\"text\"] for key, val in original_data_dict.items()}\n",
    "\n",
    "# NaNを削除\n",
    "df_compare = df_compare.dropna()\n",
    "\n",
    "# 一致しているか\n",
    "df_compare[\"is_match_all\"] = df_compare[\"original\"] == df_compare[\"predicted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/df_compare.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_compare, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解率\n",
    "accuracy = df_compare[\"is_match\"].sum() / len(df_compare)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_dict\n",
    "# original_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = calculate_cost(total_input_tokens, total_output_tokens, MODEL_NAME)\n",
    "\n",
    "print(f\"Total input tokens: {total_input_tokens}\")\n",
    "print(f\"Total output tokens: {total_output_tokens}\")\n",
    "print(f\"Total cost: ${cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
