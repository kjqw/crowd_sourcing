{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットクラスの作成\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    データセットクラス\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    encodings : dict\n",
    "        エンコーディングされたデータ\n",
    "    labels : list\n",
    "        ラベルのリスト\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    item : dict\n",
    "        エンコーディングされたデータとラベルのペア\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "# データの前処理\n",
    "def preprocess_data(data: pd.DataFrame, label_col: str) -> tuple:\n",
    "    \"\"\"\n",
    "    データの前処理\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        データ\n",
    "    label_col : str\n",
    "        ラベルのカラム名\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    encodings : dict\n",
    "        エンコーディングされたデータ\n",
    "    labels : list\n",
    "        ラベルのリスト\n",
    "    \"\"\"\n",
    "\n",
    "    encodings = tokenizer(\n",
    "        data[\"文章\"].tolist(),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    labels = data[label_col].tolist()\n",
    "    return encodings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価指標の計算関数\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "    1: {\"MODEL_NAME\": \"google-bert/bert-base-multilingual-cased\", \"min_length\": 10},\n",
    "    2: {\"MODEL_NAME\": \"google-bert/bert-base-multilingual-cased\", \"min_length\": 20},\n",
    "    3: {\"MODEL_NAME\": \"tohoku-nlp/bert-base-japanese-v3\", \"min_length\": 10},\n",
    "    4: {\"MODEL_NAME\": \"tohoku-nlp/bert-base-japanese-v3\", \"min_length\": 20},\n",
    "}\n",
    "\n",
    "# # モデルの選択\n",
    "# MODEL_NAME = \"google-bert/bert-base-multilingual-cased\"\n",
    "# # MODEL_NAME = \"tohoku-nlp/bert-base-japanese-v3\"\n",
    "\n",
    "# # 学習データの最小文字数\n",
    "# min_length = 10\n",
    "# # min_length = 20\n",
    "for i, pattern in patterns.items():\n",
    "    MODEL_NAME = pattern[\"MODEL_NAME\"]\n",
    "    min_length = pattern[\"min_length\"]\n",
    "    # パスの管理\n",
    "    data_path = Path(\"data\")\n",
    "    input_data_path = data_path / f\"data_long_texts_{min_length}.tsv\"\n",
    "    satisfaction_model_path = data_path / f\"ModelSatisfaction_{MODEL_NAME.split(\"/\")[-1]}_TextMinLength{min_length}\"\n",
    "    label_model_path = data_path / f\"ModelLabel_{MODEL_NAME.split(\"/\")[-1]}_TextMinLength{min_length}\"\n",
    "\n",
    "    # データの読み込み\n",
    "    data = pd.read_csv(input_data_path, sep=\"\\t\")\n",
    "\n",
    "    # 満足度のエンコード（0: 不満, 1: 満足）\n",
    "    data[\"満足度\"] = data[\"満足度\"].map({\"不満\": 0, \"満足\": 1})\n",
    "    \n",
    "    # ラベルのエンコード\n",
    "    label_encoder = LabelEncoder()\n",
    "    data[\"ラベル\"] = label_encoder.fit_transform(data[\"ラベル\"])\n",
    "    num_labels = len(label_encoder.classes_)\n",
    "\n",
    "    # データを訓練データとテストデータに分割\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "    # デバイスの設定\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    # モデルとトークナイザーのロード\n",
    "    tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # 満足度分類モデルのロード\n",
    "    satisfaction_model = BertForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, num_labels=2\n",
    "    )\n",
    "    satisfaction_model.to(device)  # モデルをデバイスに移動\n",
    "\n",
    "    # ラベル分類モデルのロード\n",
    "    label_model = BertForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, num_labels=num_labels\n",
    "    )\n",
    "    label_model.to(device)  # モデルをデバイスに移動\n",
    "    # 満足度分類用データセットの作成\n",
    "    satisfaction_encodings, satisfaction_labels = preprocess_data(train_data, \"満足度\")\n",
    "    satisfaction_dataset = CustomDataset(satisfaction_encodings, satisfaction_labels)\n",
    "\n",
    "    # ラベル分類用データセットの作成\n",
    "    label_encodings, label_labels = preprocess_data(train_data, \"ラベル\")\n",
    "    label_dataset = CustomDataset(label_encodings, label_labels)\n",
    "    # トレーニング引数の設定\n",
    "    train_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "    # 満足度分類モデルのトレーナーの作成\n",
    "    satisfaction_trainer = Trainer(\n",
    "        model=satisfaction_model,\n",
    "        args=train_args,\n",
    "        train_dataset=satisfaction_dataset,\n",
    "        eval_dataset=satisfaction_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    # 満足度分類モデルのトレーニング\n",
    "    satisfaction_trainer.train()\n",
    "    # モデルの保存\n",
    "    satisfaction_trainer.save_model(satisfaction_model_path)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # ラベル分類モデルのトレーナーの作成\n",
    "    label_trainer = Trainer(\n",
    "        model=label_model,\n",
    "        args=train_args,\n",
    "        train_dataset=label_dataset,\n",
    "        eval_dataset=label_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    # ラベル分類モデルのトレーニング\n",
    "    label_trainer.train()\n",
    "    # モデルの保存\n",
    "    label_trainer.save_model(label_model_path)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # どの文章がテストデータであったかを記録しておく\n",
    "    test_data_path = data_path / f\"TestData_{MODEL_NAME.split('/')[-1]}_TextMinLength{min_length}.pickle\"\n",
    "    with open(test_data_path, \"wb\") as f:\n",
    "        pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # テストデータの準備\n",
    "# test_texts = test_data[\"文章\"].tolist()\n",
    "# test_satisfactions = [\"満足\" if i == 1 else \"不満\" for i in test_data[\"満足度\"]]\n",
    "# test_labels = test_data[\"ラベル\"].tolist()\n",
    "\n",
    "# # テストデータのトークナイズ\n",
    "# test_encodings = tokenizer(\n",
    "#     test_texts, truncation=True, padding=True, return_tensors=\"pt\"\n",
    "# ).to(device)\n",
    "\n",
    "# # モデルを評価モードに設定\n",
    "# satisfaction_model.eval()\n",
    "# label_model.eval()\n",
    "\n",
    "# # 予測の取得\n",
    "# with torch.no_grad():\n",
    "#     satisfaction_outputs = satisfaction_model(**test_encodings)\n",
    "#     satisfaction_preds = torch.argmax(satisfaction_outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "#     label_outputs = label_model(**test_encodings)\n",
    "#     label_preds = torch.argmax(label_outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "# # 数値から文字列に変換\n",
    "# label_result = label_encoder.inverse_transform(label_preds).tolist()\n",
    "# satisfaction_result = [\"満足\" if pred == 1 else \"不満\" for pred in satisfaction_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_compare_test_data = pd.DataFrame(\n",
    "#     {\n",
    "#         \"満足度\": test_satisfactions,\n",
    "#         \"満足度予測\": satisfaction_result,\n",
    "#         \"満足度一致\": [i == j for i, j in zip(test_satisfactions, satisfaction_result)],\n",
    "#         \"ラベル\": test_labels,\n",
    "#         \"ラベル予測\": label_result,\n",
    "#         \"ラベル一致\": [i == j for i, j in zip(test_labels, label_result)],\n",
    "#         \"文章\": test_texts,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_compare_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # どの文章がテストデータであったかを記録しておく\n",
    "# test_data_path = data_path / f\"TestTexts_{MODEL_NAME.split('/')[-1]}_TextMinLength{min_length}.pickle\"\n",
    "# with open(test_data_path, \"wb\") as f:\n",
    "#     pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
