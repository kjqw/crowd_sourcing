{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "\n",
    "import numpy as np  # 数値計算用ライブラリ\n",
    "import pandas as pd  # データ操作用ライブラリ\n",
    "import torch  # PyTorchのインポート\n",
    "from sklearn.model_selection import train_test_split  # データ分割のための関数\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    Dataset,\n",
    ")  # データローダーとデータセットのインポート\n",
    "from tqdm import tqdm  # プログレスバーの表示\n",
    "from transformers import (  # Transformersライブラリからのモデルとトークナイザのインポート\n",
    "    AdamW,\n",
    "    BertForSequenceClassification,\n",
    "    BertModel,\n",
    "    BertTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "df = pd.read_csv(\"training_data_without_nan.tsv\", sep=\"\\t\")\n",
    "\n",
    "# ラベルとテキストの抽出\n",
    "df[\"label\"] = (\n",
    "    df[\"ラベル\"].astype(\"category\").cat.codes\n",
    ")  # ラベルをカテゴリから数値に変換\n",
    "labels = df[\"ラベル\"].astype(\"category\").cat.categories.tolist()  # カテゴリリストを取得\n",
    "df[\"text\"] = df[\"文章\"]  # テキストデータを抽出\n",
    "df[\"satisfaction\"] = df[\"満足度\"]  # 満足度データを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの設定\n",
    "# MODEL_NAME = \"cl-tohoku/bert-base-japanese\"\n",
    "# MODEL_NAME = \"cl-tohoku/bert-base-japanese-v3\"\n",
    "MODEL_NAME = \"cl-tohoku/bert-large-japanese-v2\"\n",
    "\n",
    "# トークナイザーとモデルの読み込み\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model_before_trained = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=len(labels)\n",
    ")\n",
    "\n",
    "# 学習された重みを読み込む\n",
    "# model_path = \"model_bert_base_japanese_v3.pth\"\n",
    "model_path = \"model_bert_large_japanese_v2.pth\"\n",
    "model_after_trained = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=len(labels)\n",
    ")\n",
    "model_after_trained.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_before_trained.to(device)\n",
    "model_after_trained.to(device)\n",
    "\n",
    "# 損失関数の定義\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測関数\n",
    "def predict(\n",
    "    text: str,\n",
    "    model: BertForSequenceClassification,\n",
    "    tokenizer: BertTokenizer,\n",
    "    device: torch.device,\n",
    "    top_k: int = 1,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    テキストのカテゴリと満足度を予測する関数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        予測対象のテキスト\n",
    "    model : BertForSequenceClassification\n",
    "        予測に使用する事前学習済みモデル\n",
    "    tokenizer : BertTokenizer\n",
    "        トークナイザー\n",
    "    device : torch.device\n",
    "        使用するデバイス (CPUまたはGPU)\n",
    "    top_k : int, optional\n",
    "        上位何カテゴリを表示するか (デフォルトは1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        予測結果 (カテゴリと満足度)\n",
    "    \"\"\"\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        return_token_type_ids=False,\n",
    "        padding=\"max_length\",\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits  # 出力ロジットを取得\n",
    "    satisfaction = torch.tanh(\n",
    "        logits[:, -1]\n",
    "    ).squeeze()  # tanh関数を使用して-1から1の範囲に収める\n",
    "    # satisfaction = logits[:, -1]\n",
    "\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "    top_probs, top_classes = torch.topk(probs, top_k, dim=1)\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(top_k):\n",
    "        predictions.append(\n",
    "            {\n",
    "                \"category\": labels[top_classes[0][i]],\n",
    "                \"confidence\": top_probs[0][i].item(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"predictions\": predictions,\n",
    "        \"satisfaction\": satisfaction.item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例\n",
    "example_texts = [\n",
    "    \"行きたいところにすぐに行ける\",\n",
    "    \"子供が喜ぶ施設が多い\",\n",
    "    \"食事が美味しい\",\n",
    "    \"自然が多い\",\n",
    "    \"アクセスが悪い\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習前のモデルで予測\n",
    "for example_text in example_texts:\n",
    "    prediction = predict(example_text, model_before_trained, tokenizer, device)\n",
    "    print(f\"Text: {example_text}\")\n",
    "    print(f\"Prediction Category: {prediction['predictions']}\")\n",
    "    # print(f\"Satisfaction: {prediction['satisfaction']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習後のモデルで予測\n",
    "for example_text in example_texts:\n",
    "    prediction = predict(example_text, model_after_trained, tokenizer, device)\n",
    "    print(f\"Text: {example_text}\")\n",
    "    print(f\"Prediction Category: {prediction['predictions']}\")\n",
    "    # print(f\"Satisfaction: {prediction['satisfaction']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
