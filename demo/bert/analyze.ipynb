{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import japanize_matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの選択\n",
    "# MODEL_NAME = \"google-bert/bert-base-multilingual-cased\"\n",
    "MODEL_NAME = \"tohoku-nlp/bert-base-japanese-v3\"\n",
    "\n",
    "# 学習データの最小文字数\n",
    "min_length = 10\n",
    "# min_length = 20\n",
    "\n",
    "# パスの管理\n",
    "data_path = Path(\"data\")\n",
    "input_data_path = data_path / f\"data_long_texts_{min_length}.tsv\"\n",
    "satisfaction_model_path = data_path / f\"ModelSatisfaction_{MODEL_NAME.split(\"/\")[-1]}_TextMinLength{min_length}\"\n",
    "label_model_path = data_path / f\"ModelLabel_{MODEL_NAME.split(\"/\")[-1]}_TextMinLength{min_length}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data = pd.read_csv(input_data_path, sep=\"\\t\")\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルのエンコード\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit_transform(data[\"ラベル\"])\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "data[\"満足度\"] = [\"満足\" if i == 1 else \"不満\" for i in data[\"満足度\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルとトークナイザーのロード\n",
    "\n",
    "# トークナイザーのロード\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# 満足度分類モデルのロード\n",
    "satisfaction_model = BertForSequenceClassification.from_pretrained(\n",
    "    satisfaction_model_path\n",
    ")\n",
    "satisfaction_model.to(device)  # モデルをデバイスに移動\n",
    "\n",
    "# ラベル分類モデルのロード\n",
    "label_model = BertForSequenceClassification.from_pretrained(label_model_path)\n",
    "label_model.to(device)  # モデルをデバイスに移動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価したいテキストの読み込み\n",
    "\n",
    "use_all_data_for_evaluation = True  # Trueの場合、すべてのデータを使用して評価を行う。 Falseの場合、テストデータのみを使用する。\n",
    "use_all_data_for_evaluation = False\n",
    "\n",
    "if use_all_data_for_evaluation:\n",
    "    texts_df = data\n",
    "    texts = texts_df[\"文章\"].tolist()\n",
    "else:\n",
    "    with open(\n",
    "        data_path\n",
    "        / f\"TestData_{MODEL_NAME.split('/')[-1]}_TextMinLength{min_length}.pickle\",\n",
    "        \"rb\",\n",
    "    ) as f:\n",
    "        texts_df = pickle.load(f)\n",
    "    texts_df = texts_df.sort_index()  # インデックスの整合性を保つためにソート\n",
    "    texts_df[\"満足度\"] = [\"満足\" if i == 1 else \"不満\" for i in texts_df[\"満足度\"]] # ラベルを文字列に変換\n",
    "    texts_df[\"ラベル\"] = label_encoder.inverse_transform(texts_df[\"ラベル\"]) # ラベルを文字列に変換\n",
    "    texts = texts_df[\"文章\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデルで分類\n",
    "with torch.no_grad():\n",
    "    # 満足度の予測\n",
    "    satisfaction_texts = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    satisfaction_texts = satisfaction_texts.to(device)\n",
    "    satisfaction_outputs = satisfaction_model(**satisfaction_texts)\n",
    "    satisfaction_predictions = torch.argmax(satisfaction_outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "    # ラベルの予測\n",
    "    label_texts = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    label_texts = label_texts.to(device)\n",
    "    label_outputs = label_model(**label_texts)\n",
    "    label_predictions = torch.argmax(label_outputs.logits, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpuのメモリ解放\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値から文字列に変換\n",
    "satisfaction_predictions_str = [\n",
    "    \"満足\" if i == 1 else \"不満\" for i in satisfaction_predictions\n",
    "]\n",
    "label_predictions_str = label_encoder.inverse_transform(label_predictions).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測との比較\n",
    "df_compare = pd.DataFrame(\n",
    "    {\n",
    "        \"満足度\": texts_df[\"満足度\"],\n",
    "        \"満足度予測\": satisfaction_predictions_str,\n",
    "        \"満足度一致\": texts_df[\"満足度\"] == satisfaction_predictions_str,\n",
    "        \"ラベル\": texts_df[\"ラベル\"],\n",
    "        \"ラベル予測\": label_predictions_str,\n",
    "        \"ラベル一致\": texts_df[\"ラベル\"] == label_predictions_str,\n",
    "        \"文章\": texts,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルの分類結果の可視化\n",
    "\n",
    "# ラベルごとのデータ数をカウント\n",
    "label_counts = Counter(df_compare[\"ラベル\"])\n",
    "# ラベルごとの一致数をカウント\n",
    "label_correct_counts = Counter(df_compare[df_compare[\"ラベル一致\"]][\"ラベル\"])\n",
    "# ラベルが他のラベルに予測された数をカウント\n",
    "label_misclassified_as_other_counts = Counter(\n",
    "    df_compare[~df_compare[\"ラベル一致\"]][\"ラベル\"]\n",
    ")\n",
    "# 他のラベルがラベルに予測された数をカウント\n",
    "label_other_misclassified_as_label_counts = Counter(\n",
    "    df_compare[~df_compare[\"ラベル一致\"]][\"ラベル予測\"]\n",
    ")\n",
    "\n",
    "labels = sorted(label_counts.keys())\n",
    "\n",
    "original_counts = [label_counts[label] for label in labels]\n",
    "correct_counts = [label_correct_counts.get(label, 0) for label in labels]\n",
    "misclassified_as_other_counts = [\n",
    "    label_misclassified_as_other_counts.get(label, 0) for label in labels\n",
    "]\n",
    "other_misclassified_as_label_counts = [\n",
    "    label_other_misclassified_as_label_counts.get(label, 0) for label in labels\n",
    "]\n",
    "\n",
    "x = range(len(labels))\n",
    "\n",
    "# プロットの作成\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.2\n",
    "\n",
    "# もともとのラベルのデータ数\n",
    "ax.bar(\n",
    "    x,\n",
    "    original_counts,\n",
    "    bar_width,\n",
    "    label=\"元のラベル数\",\n",
    "    align=\"center\",\n",
    "    color=\"tab:blue\",\n",
    "    hatch=\"//\",\n",
    ")\n",
    "# もとのラベルとラベル予測が一致したデータ数\n",
    "ax.bar(\n",
    "    [i + bar_width for i in x],\n",
    "    correct_counts,\n",
    "    bar_width,\n",
    "    label=\"予測の一致数\",\n",
    "    align=\"center\",\n",
    "    color=\"tab:green\",\n",
    "    hatch=\"-\",\n",
    ")\n",
    "# もとのラベルに他のラベルが予測されたデータ数\n",
    "ax.bar(\n",
    "    [i + 2 * bar_width for i in x],\n",
    "    misclassified_as_other_counts,\n",
    "    bar_width,\n",
    "    label=\"他のラベルとして予測された数\",\n",
    "    align=\"center\",\n",
    "    color=\"tab:red\",\n",
    "    hatch=\"+\",\n",
    ")\n",
    "# 他のラベルがラベルに予測されたデータ数\n",
    "ax.bar(\n",
    "    [i + 3 * bar_width for i in x],\n",
    "    other_misclassified_as_label_counts,\n",
    "    bar_width,\n",
    "    label=\"他のラベルから予測された数\",\n",
    "    align=\"center\",\n",
    "    color=\"tab:orange\",\n",
    "    hatch=\"x\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"ラベル\")\n",
    "ax.set_ylabel(\"件数\")\n",
    "# ax.set_title(\"ラベルごとの分類結果\")\n",
    "ax.set_xticks([i + 1.5 * bar_width for i in x])\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = (\n",
    "    data_path\n",
    "    / f\"LabelClassificationResult_{MODEL_NAME.split('/')[-1]}_TextMinLength{min_length}_{'AllData' if use_all_data_for_evaluation else 'TestData'}.png\"\n",
    ")\n",
    "fig.savefig(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルの分類結果の可視化（ラベルごとにソート）\n",
    "\n",
    "# ラベルを元のラベル数でソート\n",
    "sorted_labels = sorted(\n",
    "    label_counts.keys(), key=lambda label: label_counts[label], reverse=True\n",
    ")\n",
    "\n",
    "sorted_original_counts = [label_counts[label] for label in sorted_labels]\n",
    "sorted_correct_counts = [label_correct_counts.get(label, 0) for label in sorted_labels]\n",
    "sorted_misclassified_as_other_counts = [\n",
    "    label_misclassified_as_other_counts.get(label, 0) for label in sorted_labels\n",
    "]\n",
    "sorted_other_misclassified_as_label_counts = [\n",
    "    label_other_misclassified_as_label_counts.get(label, 0) for label in sorted_labels\n",
    "]\n",
    "\n",
    "x = range(len(sorted_labels))\n",
    "\n",
    "# プロットの作成\n",
    "fig_sorted, ax_sorted = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.2\n",
    "\n",
    "# もともとのラベルのデータ数\n",
    "ax_sorted.bar(\n",
    "    x,\n",
    "    sorted_original_counts,\n",
    "    bar_width,\n",
    "    label=\"元のラベル数\",\n",
    "    align=\"center\",\n",
    "    color=\"tab:blue\",\n",
    "    hatch=\"//\",\n",
    ")\n",
    "# もとのラベルとラベル予測が一致したデータ数\n",
    "ax_sorted.bar(\n",
    "    [i + bar_width for i in x],\n",
    "    sorted_correct_counts,\n",
    "    bar_width,\n",
    "    label=\"予測の一致数\",\n",
    "    align=\"center\",\n",
    "    color=\"tab:green\",\n",
    "    hatch=\"-\",\n",
    ")\n",
    "# もとのラベルに他のラベルが予測されたデータ数\n",
    "ax_sorted.bar(\n",
    "    [i + 2 * bar_width for i in x],\n",
    "    sorted_misclassified_as_other_counts,\n",
    "    bar_width,\n",
    "    label=\"他のラベルとして予測された数\",\n",
    "    align=\"center\",\n",
    "    color=\"tab:red\",\n",
    "    hatch=\"+\",\n",
    ")\n",
    "# 他のラベルがラベルに予測されたデータ数\n",
    "ax_sorted.bar(\n",
    "    [i + 3 * bar_width for i in x],\n",
    "    sorted_other_misclassified_as_label_counts,\n",
    "    bar_width,\n",
    "    label=\"他のラベルから予測された数\",\n",
    "    align=\"center\",\n",
    "    color=\"tab:orange\",\n",
    "    hatch=\"x\",\n",
    ")\n",
    "\n",
    "ax_sorted.set_xlabel(\"ラベル\")\n",
    "ax_sorted.set_ylabel(\"件数\")\n",
    "# ax_sorted.set_title(\"ラベルごとの分類結果\")\n",
    "ax_sorted.set_xticks([i + 1.5 * bar_width for i in x])\n",
    "ax_sorted.set_xticklabels(sorted_labels, rotation=90)\n",
    "ax_sorted.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sorted_path = (\n",
    "    data_path\n",
    "    / f\"LabelClassificationResultSorted_{MODEL_NAME.split('/')[-1]}_TextMinLength{min_length}_{'AllData' if use_all_data_for_evaluation else 'TestData'}.png\"\n",
    ")\n",
    "fig_sorted.savefig(fig_sorted_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
